{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples for demonstrating different classification techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "attributes": {
     "classes": [
      "input}/"
     ],
     "id": "",
     "n": "1"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "\n",
    "import numpy as np\n",
    "import xarray as xa\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import exposure # We are going to rescale the image\n",
    "import sklearn as skl\n",
    "from sklearn.cluster import KMeans # Unsupervised learning\n",
    "from sklearn.neural_network import MLPClassifier # Supervised learning\n",
    "from matplotlib.colors import ListedColormap # For colourmap\n",
    "from matplotlib import patches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have now imported some libraries and will load some Sentinel 2 OpenDAP NetCDF\n",
    "data from https://satellittdata.no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "2"
    }
   },
   "outputs": [],
   "source": [
    "url = 'https://nbstds.met.no/thredds/dodsC/NBS/S2A/2021/07/14/S2A_MSIL1C_20210714T105031_N0301_R051_T33WWR_20210714T130146.nc'\n",
    "dset = xa.open_dataset(url+'#fillmismatch') # opening OpenDAP NetCDF dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having opened the dataset we can how have a look at the header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "3"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset>\n",
      "Dimensions:                                             (dimension_rgb: 3, time: 1, x: 10980, y: 10980)\n",
      "Coordinates:\n",
      "  * time                                                (time) datetime64[ns] ...\n",
      "  * x                                                   (x) int32 499980 ... ...\n",
      "  * y                                                   (y) int32 7600020 ......\n",
      "    lat                                                 (y, x) float32 ...\n",
      "    lon                                                 (y, x) float32 ...\n",
      "Dimensions without coordinates: dimension_rgb\n",
      "Data variables: (12/71)\n",
      "    TCI                                                 (dimension_rgb, y, x) float32 ...\n",
      "    UTM_projection                                      int32 ...\n",
      "    S2_Level_1C_Product_Metadata                        |S64 ...\n",
      "    INSPIRE_Metadata                                    |S64 ...\n",
      "    S2_Level_1C_Datastrip1_Metadata                     |S64 ...\n",
      "    Format_OLQC_Report_Datastrip1_InformationData       |S64 ...\n",
      "    ...                                                  ...\n",
      "    view_zenith_B10                                     (time, y, x) float32 ...\n",
      "    view_azimuth_B10                                    (time, y, x) float32 ...\n",
      "    view_zenith_B11                                     (time, y, x) float32 ...\n",
      "    view_azimuth_B11                                    (time, y, x) float32 ...\n",
      "    view_zenith_B12                                     (time, y, x) float32 ...\n",
      "    view_azimuth_B12                                    (time, y, x) float32 ...\n",
      "Attributes: (12/42)\n",
      "    title:                               Sentinel-2 Level-1C data\n",
      "    netcdf4_version_id:                  4.7.4\n",
      "    file_creation_date:                  2021-07-14T16:22:38Z\n",
      "    CLOUD_COVERAGE_ASSESSMENT:           15.579300000000002\n",
      "    DATATAKE_1_DATATAKE_SENSING_START:   2021-07-14T10:50:31.024Z\n",
      "    DATATAKE_1_DATATAKE_TYPE:            INS-NOBS\n",
      "    ...                                  ...\n",
      "    history:                             2021-07-14T16:22:38Z. Converted from...\n",
      "    source:                              surface observation\n",
      "    orbitNumber:                         031651\n",
      "    relativeOrbitNumber:                 51\n",
      "    DODS.strlen:                         3815\n",
      "    DODS.dimName:                        dimension_SAFE_structure\n"
     ]
    }
   ],
   "source": [
    "print(dset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that it contains coordinates, variables, and attributes. We can for\n",
    "instance take a closer look at the time coordinate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "4"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.DataArray 'time' (time: 1)>\n",
      "array(['2021-07-14T10:50:31.000000000'], dtype='datetime64[ns]')\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 2021-07-14T10:50:31\n",
      "Attributes:\n",
      "    long_name:  reference time of satellite image\n"
     ]
    }
   ],
   "source": [
    "print(dset.time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and the B2 data variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "5"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.DataArray 'B2' (time: 1, y: 10980, x: 10980)>\n",
      "[120560400 values with dtype=float32]\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 2021-07-14T10:50:31\n",
      "  * x        (x) int32 499980 499990 500000 500010 ... 609750 609760 609770\n",
      "  * y        (y) int32 7600020 7600010 7600000 ... 7490250 7490240 7490230\n",
      "    lat      (y, x) float32 ...\n",
      "    lon      (y, x) float32 ...\n",
      "Attributes:\n",
      "    units:                  1\n",
      "    grid_mapping:           UTM_projection\n",
      "    standard_name:          toa_bidirectional_reflectance\n",
      "    long_name:              Reflectance in band B2\n",
      "    bandwidth:              65\n",
      "    bandwidth_unit:         nm\n",
      "    wavelength:             490\n",
      "    wavelength_unit:        nm\n",
      "    solar_irradiance:       1959.66\n",
      "    solar_irradiance_unit:  W/m2/um\n",
      "    _ChunkSizes:            [ 1 32 32]\n"
     ]
    }
   ],
   "source": [
    "print(dset.B2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What is B2?**\n",
    "\n",
    "We can plot B2 to see it better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "10"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87f32f93adfe41998e07d6285bc030e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# East - west\n",
    "xmin = 9000\n",
    "xmax = -1\n",
    "\n",
    "# North - south\n",
    "ymin = 0\n",
    "ymax = 2000\n",
    "\n",
    "plt.figure()\n",
    "view =dset.B2[0,ymin:ymax,xmin:xmax]\n",
    "view.plot(cmap='Greys',vmax=1000)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "7"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.DataArray 'TCI' (dimension_rgb: 3, y: 10980, x: 10980)>\n",
      "[361681200 values with dtype=float32]\n",
      "Coordinates:\n",
      "  * x        (x) int32 499980 499990 500000 500010 ... 609750 609760 609770\n",
      "  * y        (y) int32 7600020 7600010 7600000 ... 7490250 7490240 7490230\n",
      "    lat      (y, x) float32 ...\n",
      "    lon      (y, x) float32 ...\n",
      "Dimensions without coordinates: dimension_rgb\n",
      "Attributes:\n",
      "    long_name:     TCI RGB from B4, B3 and B2\n",
      "    grid_mapping:  UTM_projection\n",
      "    units:         1\n",
      "    _ChunkSizes:   [   1 3660 3660]\n"
     ]
    }
   ],
   "source": [
    "print(dset.TCI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "11"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2644c1e69e04fc6a76a84703c74865b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "extent = np.asarray(\n",
    "            [dset.lon[ymin,xmin].data, dset.lon[ymin,xmax].data,\n",
    "            dset.lat[ymax,xmax].data, dset.lat[ymin,xmin].data]\n",
    "         ) # To get the axis labels correct we define an extent\n",
    "\n",
    "#print('lon and lat',(extent)) # These are the latitudes and longitudes\n",
    "n=0\n",
    "# Reading in some parts of the r b g bands\n",
    "b = dset.B2[n,ymin:ymax,xmin:xmax]/float(dset.attrs['QUANTIFICATION_VALUE'])\n",
    "g = dset.B3[n,ymin:ymax,xmin:xmax]/float(dset.attrs['QUANTIFICATION_VALUE'])\n",
    "r = dset.B4[n,ymin:ymax,xmin:xmax]/float(dset.attrs['QUANTIFICATION_VALUE'])\n",
    "\n",
    "P0, P1 = (0, 0.15) # These are the percentages we are going to rescale on \n",
    "\n",
    "# Rescaling the exposures using scikit-image \n",
    "r = exposure.rescale_intensity(r,in_range=(P0,P1))\n",
    "g = exposure.rescale_intensity(g,in_range=(P0,P1))\n",
    "b = exposure.rescale_intensity(b,in_range=(P0,P1))\n",
    "\n",
    "# Making the RGB image\n",
    "rgb = np.dstack((r,g,b))\n",
    "\n",
    "# Clipping it\n",
    "rgb[rgb>1]=1.0\n",
    "\n",
    "\n",
    "# Plotting the RGB image\n",
    "plt.figure(figsize=(7,6))\n",
    "plt.imshow(rgb, interpolation='none', aspect='auto', extent = extent)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalized difference vegetation index (NDVI)\n",
    "Is a measure for how much vegitation there is in a pixel. More information can be found in the book (10.6), \n",
    "https://custom-scripts.sentinel-hub.com/sentinel-2/ndvi/\n",
    "and\n",
    "https://en.wikipedia.org/wiki/Normalized_difference_vegetation_index\n",
    "\n",
    "It is given by:\n",
    "$\\text{NDVI} = \\frac{\\textrm{NIR}-\\textrm{RED}}{\\textrm{NIR}+\\textrm{RED}}$\n",
    "\n",
    "which for Sentinel-2 becomes:\n",
    "\n",
    "$\\text{NDVI} = \\frac{\\textrm{B8}-\\textrm{B4}}{\\textrm{B8}+\\textrm{B4}}$\n",
    "\n",
    "We are now going to test it, though we are using L1C data. Normally one would use L2A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4fdcfa72cff43ec9848f77746c43317",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ndvi = (dset.B8[n,ymin:ymax,xmin:xmax] -dset.B4[n,ymin:ymax,xmin:xmax])/(dset.B8[n,ymin:ymax,xmin:xmax] +dset.B4[n,ymin:ymax,xmin:xmax])\n",
    "plt.figure(figsize=(7,6))\n",
    "plt.imshow(ndvi, interpolation='none', aspect='auto', extent = extent)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalized difference water index (NDWI)\n",
    "Measures how much water there is in the pixel as part of a water body.  More information can be found at:\n",
    "https://custom-scripts.sentinel-hub.com/sentinel-2/ndwi/\n",
    "og \n",
    "https://en.wikipedia.org/wiki/Normalized_difference_water_index\n",
    "\n",
    "\n",
    "It is given by:\n",
    "$\\text{NDWI} = \\frac{\\textrm{GREEN}-\\textrm{NIR}}{\\textrm{GREEN}+\\textrm{NIR}}$\n",
    "\n",
    "\n",
    "which for Sentinel-2 becomes:\n",
    "\n",
    "$\\text{NDWI} = \\frac{\\textrm{B3}-\\textrm{B8}}{\\textrm{B3}+\\textrm{B8}}$\n",
    "\n",
    "We are now going to test it, though we are using L1C data. Normally one would use L2A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "303a970701324807b8a030aad57e8354",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ndwi = (dset.B3[n,ymin:ymax,xmin:xmax] -dset.B8[n,ymin:ymax,xmin:xmax])/(dset.B3[n,ymin:ymax,xmin:xmax] +dset.B8[n,ymin:ymax,xmin:xmax])\n",
    "plt.figure(figsize=(7,6))\n",
    "plt.imshow(ndwi, interpolation='none', aspect='auto', extent = extent)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unsupervised learning\n",
    "\n",
    "This is learning where we as the computer to classify the area based on a given model. In this case we are going to use [scikit-learn](https://scikit-learn.org/stable/)\n",
    "and the method [K-means](https://scikit-learn.org/stable/modules/clustering.html#k-means) to cluster data. It is based on the minimising the variance in the cluster, though something called its intertia. The link above has an excellent explanation.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3958000, 4)\n",
      "(3958000,)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e45ce29529d7475181f81bc246e1275b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "  # We are first going to make the dataset, which here is going to be rgb + NIR\n",
    "\n",
    "rgbn = np.dstack((dset.B4[n,ymin:ymax,xmin:xmax],dset.B3[n,ymin:ymax,xmin:xmax],\n",
    "      dset.B2[n,ymin:ymax,xmin:xmax],dset.B8[n,ymin:ymax,xmin:xmax]))\n",
    "\n",
    "w, h, d = original_shape = tuple(rgbn.shape)\n",
    "\n",
    "rgbn_2d = np.reshape(rgbn,(w*h,d))\n",
    "print(rgbn_2d.shape)\n",
    "# We select a small subset to fit on:\n",
    "rgbn_sample = skl.utils.shuffle(rgbn_2d, random_state=0, n_samples=1_000)\n",
    "\n",
    "# We are now going to ask for a certain number of clusters\n",
    "n_clusters = 4\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=0).fit(rgbn_sample)\n",
    "\n",
    "# Predict the labels for the whole image \n",
    "# (this could also be a new image, and can be reused on multiple images)\n",
    "\n",
    "labels = kmeans.predict(rgbn_2d)\n",
    "print(labels.shape)\n",
    "\n",
    "# Show the results\n",
    "plt.figure(figsize=(7,6))\n",
    "plt.imshow(labels.reshape(w,h), interpolation='none', aspect='auto', extent = extent)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supervised learning\n",
    "\n",
    "In contrast to unsupervised learning, in supervised learning we need to teach the algorithm what a given class looks like. \n",
    "We have a range of different algorithms to choose from, and it would be to much to go through them all. \n",
    "Here we choose to use a neural network, specifically \"Multi-layer Perceptron\" from scikit-learn. You can read more about it at [Neural network models (supervised)](https://scikit-learn.org/stable/modules/neural_networks_supervised.html)\n",
    "\n",
    "There are much faster implmentations neural networks in deep learning architectures, but these require the use of GPUs and dedicated software (for instance [TensorFLow](https://www.tensorflow.org/) ). SNAP also has built in modules for supervised learning.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15c414e27a3b44acbdcf72eba55c9805",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# We first need to define som areas to learn from. We are going to look at classifying into \n",
    "# four different types and we will be using the same dataset (rgbn) as for unsupervised classification\n",
    "\n",
    "wx=[500, 700]\n",
    "wy=[250, 500]\n",
    "\n",
    "water = rgbn[wx[0]:wx[1],wy[0]:wy[1],:]\n",
    "water = np.reshape(water,(water.shape[0]*water.shape[1],d)) # making it 2d\n",
    "\n",
    "tx=[560, 660]\n",
    "ty=[860, 910]\n",
    "\n",
    "trees = rgbn[tx[0]:tx[1],ty[0]:ty[1],:]\n",
    "trees = np.reshape(trees,(trees.shape[0]*trees.shape[1],d)) # making it 2d\n",
    "\n",
    "cx=[1185, 1225]\n",
    "cy=[690, 740]\n",
    "\n",
    "clouds = rgbn[cx[0]:cx[1],cy[0]:cy[1],:]\n",
    "clouds = np.reshape(clouds,(clouds.shape[0]*clouds.shape[1],d)) # making it 2d\n",
    "\n",
    "bx=[943, 970]\n",
    "by=[920, 945]\n",
    "\n",
    "build = rgbn[bx[0]:bx[1],by[0]:by[1],:]\n",
    "build = np.reshape(build,(build.shape[0]*build.shape[1],d)) # making it 2d\n",
    "\n",
    "\n",
    "\n",
    "def plot_rect(xlim, ylim, text, col):\n",
    "    ax = plt.gca() # get current axis\n",
    "    ax.add_patch(patches.Rectangle((xlim[0], ylim[0]), ylim[1]-ylim[0], xlim[1]-xlim[0], edgecolor=col, fill=False))\n",
    "    ax.annotate(text,(xlim[1]+10, ylim[0]+(ylim[1]-ylim[0])/2), color=col, ha='left', va='center')\n",
    "    \n",
    "\n",
    "# Show where the rectangles are\n",
    "plt.figure(figsize=(7,6))\n",
    "plt.imshow(rgb, interpolation='none', aspect='equal')#, extent = extent) # Plotting it in x y coordinates and not lat lon\n",
    "plot_rect(wx, wy, \"Water\", \"red\")\n",
    "plot_rect(tx, ty, \"Trees\", \"white\")\n",
    "plot_rect(cx, cy, \"Clouds\", \"green\")\n",
    "plot_rect(bx, by, \"City\", \"black\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(57675, 4) (57675,)\n",
      "3 4\n",
      "(3958000,)\n"
     ]
    }
   ],
   "source": [
    "# Now we are going to use these to train the algorithm\n",
    "X = np.concatenate([water, trees, clouds, build])\n",
    "\n",
    "#Assigning labels 0 = water, 1 = trees, 2 = clouds, 3 = city\n",
    "y = np.concatenate([\n",
    "    np.zeros(water.shape[0]),\n",
    "    np.ones(trees.shape[0]),\n",
    "    np.ones(clouds.shape[0]) + 1,\n",
    "    np.ones(build.shape[0]) + 2])\n",
    "# \n",
    "print(X.shape,y.shape)\n",
    "# Initialise the neural network\n",
    "clf = MLPClassifier() # We are using default values\n",
    "clf.fit(X, y)\n",
    "\n",
    "# How many layers and outputs are we using:\n",
    "print(clf.n_layers_, clf.n_outputs_)\n",
    "\n",
    "labels_nn = clf.predict(rgbn_2d)\n",
    "print(labels_nn.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80482a67fcfe4f3d8deff8bd52161cee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Assigning colours to the different labels\n",
    "col_dict={0:\"blue\", # Sea\n",
    "          1:\"green\", # Trees\n",
    "          2:\"white\", # Clouds\n",
    "          3:\"black\"} # City\n",
    "\n",
    "\n",
    "cm = ListedColormap([col_dict[x] for x in col_dict.keys()])\n",
    "\n",
    "plt.figure(figsize=(7,6))\n",
    "plt.imshow(labels_nn.reshape(w,h), interpolation='none', aspect='equal', cmap=cm)#, extent = extent,cmap=cm)\n",
    "cbar = plt.colorbar( orientation='horizontal',ticks=[3/8,2*3/4-3/8,3*3/4-3/8,4*3/4-3/8])\n",
    "cbar.ax.set_xticklabels(['Sea', 'Trees', 'Clouds', 'Houses'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
